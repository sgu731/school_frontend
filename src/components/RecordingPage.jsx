import React, { useState, useRef } from "react";
import { Button } from "./ui/button";
import { useNavigate } from "react-router-dom";

export default function RecordingPage() {
  const navigate = useNavigate();
  const [recording, setRecording] = useState(false);
  const [paused, setPaused] = useState(false);
  const [recordingTime, setRecordingTime] = useState(0);
  const [transcript, setTranscript] = useState("");
  const [translated, setTranslated] = useState("");

  const mediaRecorderRef = useRef(null);
  const audioChunks = useRef([]);
  const recognitionRef = useRef(null);
  const timerRef = useRef(null);
  const enableTranslationRef = useRef(true); // âœ… ä½¿ç”¨ ref æ§åˆ¶ç¿»è­¯å‹¾é¸ç‹€æ…‹

  const startRecording = async () => {
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    mediaRecorderRef.current = new MediaRecorder(stream);
    audioChunks.current = [];

    mediaRecorderRef.current.ondataavailable = (e) => {
      if (e.data.size > 0) audioChunks.current.push(e.data);
    };

    mediaRecorderRef.current.start();
    setRecordingTime(0);
    timerRef.current = setInterval(() => setRecordingTime((prev) => prev + 1), 1000);
    setPaused(false);
    setRecording(true);
    setTranscript("");
    setTranslated("");

    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (SpeechRecognition) {
      recognitionRef.current = new SpeechRecognition();
      recognitionRef.current.continuous = true;
      recognitionRef.current.interimResults = true;
      recognitionRef.current.lang = "zh-TW";

      recognitionRef.current.onresult = (e) => {
        let finalTranscript = "";

        for (let i = e.resultIndex; i < e.results.length; ++i) {
          if (e.results[i].isFinal) {
            finalTranscript += e.results[i][0].transcript;
          }
        }

        if (finalTranscript) {
          setTranscript((prev) => prev + finalTranscript);

          if (enableTranslationRef.current) {
            (async () => {
              try {
                const detectRes = await fetch(
                  "https://translate.googleapis.com/translate_a/single?client=gtx&sl=auto&tl=zh-TW&dt=t&q=" +
                    encodeURIComponent(finalTranscript)
                );
                const detectData = await detectRes.json();
                const sourceLang = detectData[2];
                const targetLang = sourceLang.startsWith("zh") ? "en" : "zh-TW";

                if (sourceLang.startsWith(targetLang.slice(0, 2))) return;

                const transRes = await fetch(
                  `https://translate.googleapis.com/translate_a/single?client=gtx&sl=auto&tl=${targetLang}&dt=t&q=${encodeURIComponent(finalTranscript)}`
                );
                const transData = await transRes.json();
                const translatedText = transData[0].map((item) => item[0]).join("");
                setTranslated((prev) => prev + translatedText);
              } catch (err) {
                console.error("ç¿»è­¯å¤±æ•—ï¼š", err);
              }
            })();
          }
        }
      };

      recognitionRef.current.start();
    }
  };

  const stopRecording = () => {
    if (mediaRecorderRef.current && mediaRecorderRef.current.state !== "inactive") {
      mediaRecorderRef.current.stop();

      mediaRecorderRef.current.onstop = () => {
        if (audioChunks.current.length === 0) {
          alert("âš ï¸ éŒ„éŸ³å¤±æ•—ï¼Œè«‹éŒ„ä¹…ä¸€é»ï¼");
          return;
        }

        const blob = new Blob(audioChunks.current, { type: "audio/webm" });
        const url = URL.createObjectURL(blob);

        const now = new Date();
        const localTime = `${now.getFullYear()}/${(now.getMonth() + 1)
          .toString()
          .padStart(2, "0")}/${now.getDate().toString().padStart(2, "0")} ${now
          .getHours()
          .toString()
          .padStart(2, "0")}:${now.getMinutes().toString().padStart(2, "0")}`;

        const prev = JSON.parse(localStorage.getItem("voiceNotes") || "[]");
        const maxIndex = prev.reduce((max, r) => {
          const match = r.title.match(/^éŒ„éŸ³ (\d+)$/);
          const num = match ? parseInt(match[1]) : 0;
          return Math.max(max, num);
        }, 0);

        const newRecord = {
          id: Date.now(),
          title: `éŒ„éŸ³ ${maxIndex + 1}`,
          url,
          time: localTime,
          duration: `${Math.floor(recordingTime / 60)
            .toString()
            .padStart(2, "0")}:${(recordingTime % 60).toString().padStart(2, "0")}`,
          text: transcript,
          translation: translated,
        };

        localStorage.setItem("voiceNotes", JSON.stringify([...prev, newRecord]));
        alert("âœ… éŒ„éŸ³å·²å„²å­˜è‡³èªéŸ³åº«");
      };
    }

    setRecording(false);
    clearInterval(timerRef.current);
    setPaused(false);
    if (recognitionRef.current) recognitionRef.current.stop();
  };

  return (
    <div className="mt-6 p-6">
      <Button
        onClick={() => {
          stopRecording();
          navigate("/voice");
        }}
        className="mb-4"
      >
        è¿”å›
      </Button>

      <div className="flex flex-wrap items-center gap-4 mb-4">
        <Button
          onClick={recording ? stopRecording : startRecording}
          className="bg-orange-600 text-white"
        >
          {recording ? "å„²å­˜" : "ğŸ™ï¸ é–‹å§‹éŒ„éŸ³"}
        </Button>

        {recording && (
          <>
            <Button
              onClick={() => {
                if (!mediaRecorderRef.current) return;
                if (mediaRecorderRef.current.state === "recording") {
                  mediaRecorderRef.current.pause();
                  recognitionRef.current?.stop();
                  clearInterval(timerRef.current);
                  setPaused(true);
                } else if (mediaRecorderRef.current.state === "paused") {
                  mediaRecorderRef.current.resume();
                  recognitionRef.current?.start();
                  timerRef.current = setInterval(() => setRecordingTime(prev => prev + 1), 1000);
                  setPaused(false);
                }
              }}
              className="bg-yellow-500 text-white"
            >
              {paused ? "â–¶ ç¹¼çºŒ" : "â¸ æš«åœ"}
            </Button>

            <p className="text-sm text-gray-600">
              â± éŒ„éŸ³æ™‚é•·ï¼š{Math.floor(recordingTime / 60).toString().padStart(2, "0")}:{(recordingTime % 60).toString().padStart(2, "0")}
            </p>

            <div className="flex items-center gap-2">
              <label className="text-sm flex items-center gap-2">
                <input
                  type="checkbox"
                  defaultChecked={enableTranslationRef.current}
                  onChange={(e) => {
                    enableTranslationRef.current = e.target.checked;
                  }}
                />
                å•Ÿç”¨å³æ™‚ç¿»è­¯ï¼ˆè‡ªå‹•ä¸­è‹±äº’è­¯ï¼‰
              </label>
            </div>
          </>
        )}
      </div>

      {recording && (
        <div className="mt-4 p-4 bg-gray-100 rounded-lg">
          <p className="text-sm text-gray-500 mb-2">ğŸ—£ å³æ™‚èªéŸ³ï¼š</p>
          <p className="whitespace-pre-wrap">{transcript}</p>
          <p className="text-sm text-gray-500 mb-2">ğŸŒ å³æ™‚ç¿»è­¯ï¼š</p>
          <p className="text-green-700 whitespace-pre-wrap mb-4">{translated}</p>
        </div>
      )}
    </div>
  );
}